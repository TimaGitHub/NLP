{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:46.179630Z","iopub.execute_input":"2024-11-06T23:48:46.180333Z","iopub.status.idle":"2024-11-06T23:48:47.323331Z","shell.execute_reply.started":"2024-11-06T23:48:46.180288Z","shell.execute_reply":"2024-11-06T23:48:47.322300Z"}},"outputs":[{"name":"stdout","text":"--2024-11-06 23:48:47--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: 'input.txt'\n\ninput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n\n2024-11-06 23:48:47 (29.3 MB/s) - 'input.txt' saved [1115394/1115394]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:47.325239Z","iopub.execute_input":"2024-11-06T23:48:47.325585Z","iopub.status.idle":"2024-11-06T23:48:50.518049Z","shell.execute_reply.started":"2024-11-06T23:48:47.325549Z","shell.execute_reply":"2024-11-06T23:48:50.517246Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"with open('/kaggle/working/input.txt') as f:\n    text = f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:50.519265Z","iopub.execute_input":"2024-11-06T23:48:50.519692Z","iopub.status.idle":"2024-11-06T23:48:50.525281Z","shell.execute_reply.started":"2024-11-06T23:48:50.519658Z","shell.execute_reply":"2024-11-06T23:48:50.524347Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"unique = sorted(list(set(text)))\nvocab_size = len(unique)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:50.527297Z","iopub.execute_input":"2024-11-06T23:48:50.527666Z","iopub.status.idle":"2024-11-06T23:48:50.551612Z","shell.execute_reply.started":"2024-11-06T23:48:50.527633Z","shell.execute_reply":"2024-11-06T23:48:50.550742Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"it = {i: t for i, t in enumerate(unique)}\nti = {t: i for i, t in enumerate(unique)}\n\nencode = lambda input: [ti[ch] for ch in input]\ndecode = lambda input: ''.join([it[ch] for ch in input])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:50.552691Z","iopub.execute_input":"2024-11-06T23:48:50.553019Z","iopub.status.idle":"2024-11-06T23:48:50.562882Z","shell.execute_reply.started":"2024-11-06T23:48:50.552988Z","shell.execute_reply":"2024-11-06T23:48:50.562017Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data = torch.tensor(encode(text), dtype = torch.long)\nn = int(0.9 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:50.563920Z","iopub.execute_input":"2024-11-06T23:48:50.564196Z","iopub.status.idle":"2024-11-06T23:48:50.854203Z","shell.execute_reply.started":"2024-11-06T23:48:50.564166Z","shell.execute_reply":"2024-11-06T23:48:50.853191Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"len(val_data) // batch_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:30:03.769779Z","iopub.execute_input":"2024-11-07T00:30:03.770179Z","iopub.status.idle":"2024-11-07T00:30:03.776919Z","shell.execute_reply.started":"2024-11-07T00:30:03.770145Z","shell.execute_reply":"2024-11-07T00:30:03.775858Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"435"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"#val_iters = len(val_data) // batch_size\nval_iters = 400\n\n@torch.no_grad()\ndef estimate_loss():\n    model.eval()\n    losses = 0\n    for iter in range(val_iters):\n        x, y = get_batch('val')\n        x, y = x.to(device), y.to(device)\n        out, loss = model(x, y)\n        losses += loss.item()\n    model.train()\n    return losses / val_iters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:30:25.126420Z","iopub.execute_input":"2024-11-07T00:30:25.126838Z","iopub.status.idle":"2024-11-07T00:30:25.133326Z","shell.execute_reply.started":"2024-11-07T00:30:25.126797Z","shell.execute_reply":"2024-11-07T00:30:25.132313Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"time_length = 10\nbatch_size = 4\n\ndef get_batch(split):\n    if split == 'train':\n        data = train_data\n    else:\n        data = val_data\n    idx = torch.randint(0, len(data) - time_length, size=(batch_size, 1))\n    x = torch.stack([data[ix:ix + time_length] for ix in idx])\n    y = torch.stack([data[ix + 1:ix + 1 + time_length] for ix in idx])\n\n    return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:57:18.748227Z","iopub.execute_input":"2024-11-06T21:57:18.748700Z","iopub.status.idle":"2024-11-06T21:57:18.756736Z","shell.execute_reply.started":"2024-11-06T21:57:18.748656Z","shell.execute_reply":"2024-11-06T21:57:18.755211Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\n\nembd_dim = vocab_size\nn_embd = vocab_size\nlr = 1e-3\niters = 10000\nval_interval = 1000\n\nclass BgramRNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embd = nn.Embedding(n_embd, embd_dim)\n\n    def forward(self, x, target=None):\n        # x -> (B, T), target -> (B, T)\n        logits = self.embd(x) # -> (B, T, C)\n\n        if target is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C) # -> (B*T, C)\n            target = target.view(B*T) # -> (B*T, 1)\n            loss = F.cross_entropy(logits, target)\n\n        return logits, loss\n\n    def generate(self, idx, max_length):\n        # idx -> (1, 1)\n        for t in range(max_length):\n            logits, _ = self(idx)\n            logits = logits[:,-1,:]\n            probs = logits.softmax(dim=-1)\n            pred = torch.multinomial(probs, 1) # -> (1,1)\n            idx = torch.cat([idx, pred], dim=1)\n\n        return idx\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:48:55.080189Z","iopub.execute_input":"2024-11-06T23:48:55.080911Z","iopub.status.idle":"2024-11-06T23:48:55.090790Z","shell.execute_reply.started":"2024-11-06T23:48:55.080869Z","shell.execute_reply":"2024-11-06T23:48:55.089778Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = BgramRNN()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T22:30:21.397807Z","iopub.execute_input":"2024-11-06T22:30:21.398302Z","iopub.status.idle":"2024-11-06T22:30:21.404642Z","shell.execute_reply.started":"2024-11-06T22:30:21.398258Z","shell.execute_reply":"2024-11-06T22:30:21.403357Z"}},"outputs":[],"execution_count":259},{"cell_type":"code","source":"context = torch.zeros((1,1), dtype=torch.long)\ndecode(model.generate(context, max_length=100)[0].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:57:23.661351Z","iopub.execute_input":"2024-11-06T21:57:23.661770Z","iopub.status.idle":"2024-11-06T21:57:23.688061Z","shell.execute_reply.started":"2024-11-06T21:57:23.661732Z","shell.execute_reply":"2024-11-06T21:57:23.686836Z"}},"outputs":[{"execution_count":180,"output_type":"execute_result","data":{"text/plain":"'\\nw\\nIw-?gg?gRfbHby:NkY.ouOYehntMe\\nugn?q$QyOPyWua$zz$pljoQSZbz:rIw&&RfPSN&c-ZsSh $Oqp$LevXF,giNqBa LnjJ'"},"metadata":{}}],"execution_count":180},{"cell_type":"code","source":"optim = torch.optim.Adam(model.parameters(), lr=lr)\nfor iter in range(iters):\n    x, y = get_batch('train')\n    out, loss = model(x, y)\n    if iter % val_interval == 0 or iter == iters-1:\n        val_loss = estimate_loss()\n        print(f\"Iter number: {iter}, train loss value {loss.item():.4f}, val loss value {val_loss:.4f}\")\n    model.zero_grad()\n    loss.backward()\n    optim.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:57:31.988758Z","iopub.execute_input":"2024-11-06T21:57:31.989805Z","iopub.status.idle":"2024-11-06T21:57:44.182840Z","shell.execute_reply.started":"2024-11-06T21:57:31.989755Z","shell.execute_reply":"2024-11-06T21:57:44.180852Z"}},"outputs":[{"name":"stdout","text":"Iter number: 0, train loss value 4.3925, val loss value 4.5356\nIter number: 1000, train loss value 3.9628, val loss value 3.8629\nIter number: 2000, train loss value 3.4913, val loss value 3.3996\nIter number: 3000, train loss value 3.0454, val loss value 3.0905\nIter number: 4000, train loss value 2.8103, val loss value 2.8936\nIter number: 5000, train loss value 2.3692, val loss value 2.7622\nIter number: 6000, train loss value 2.7632, val loss value 2.6727\nIter number: 7000, train loss value 2.8618, val loss value 2.6221\nIter number: 8000, train loss value 2.1723, val loss value 2.5860\nIter number: 9000, train loss value 2.4199, val loss value 2.5470\nIter number: 9999, train loss value 2.4077, val loss value 2.5242\n","output_type":"stream"}],"execution_count":181},{"cell_type":"code","source":"context = torch.zeros((1,1), dtype=torch.long)\ndecode(model.generate(context, max_length=100)[0].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T21:57:49.532868Z","iopub.execute_input":"2024-11-06T21:57:49.533809Z","iopub.status.idle":"2024-11-06T21:57:49.559150Z","shell.execute_reply.started":"2024-11-06T21:57:49.533758Z","shell.execute_reply":"2024-11-06T21:57:49.557744Z"}},"outputs":[{"execution_count":182,"output_type":"execute_result","data":{"text/plain":"'\\nALI a!zzleie bictmy,iand t oldofathibTHe hey Clle: nonthe the at mfew-MAllde thern-rd?dent:\\nNTicine '"},"metadata":{}}],"execution_count":182},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"time_length = 25\nbatch_size = 16\n\ndef get_batch(split):\n    if split == 'train':\n        data = train_data\n    else:\n        data = val_data\n    idx = torch.randint(0, len(data) - time_length, size=(batch_size, 1))\n    x = torch.stack([data[ix:ix + time_length] for ix in idx])\n    y = torch.stack([data[ix + 1:ix + 1 + time_length] for ix in idx])\n\n    return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:39:56.646207Z","iopub.execute_input":"2024-11-06T23:39:56.647214Z","iopub.status.idle":"2024-11-06T23:39:56.654484Z","shell.execute_reply.started":"2024-11-06T23:39:56.647166Z","shell.execute_reply":"2024-11-06T23:39:56.653309Z"}},"outputs":[],"execution_count":434},{"cell_type":"code","source":"embd_dim = 128\nn_embd = vocab_size\nhidden_size = 128\nlr = 3e-4\niters = 100000\nval_iters = 1000\nn_layer = 3\ndropout = 0.0\n\nclass BgramRNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embd = nn.Embedding(n_embd, embd_dim)\n        self.rnn = nn.RNN(embd_dim, hidden_size, batch_first=True, num_layers=n_layer, nonlinearity='tanh', dropout=dropout)\n        self.linear = nn.Linear(hidden_size, n_embd, bias=False)\n\n    def forward(self, x, target=None):\n        # x -> (B, T), target -> (B, T)\n        x = self.embd(x) # -> (B, T, embd_dim)\n        output, h_t = self.rnn(x) # output -> (B, T, hidden), h_t -> (B, hidden)\n        logits = self.linear(output) # -> (B, T, n_embd)\n\n        if target is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C) # -> (B*T, C)\n            target = target.view(B*T) # -> (B*T, 1)\n            loss = F.cross_entropy(logits, target)\n\n        return logits, loss\n\n    def generate(self, idx, max_length, index=0):\n        # idx -> (1, 1)\n        if index == 0: #The fastest\n            h_t = None\n            idx_prod = idx\n            for t in range(max_length): ### The fastest\n                x = self.embd(idx_prod) # -> (B, T, embd_dim)\n                output, h_t = self.rnn(x, h_t) # output -> (B, T, hidden), h_t -> (B, hidden)\n                logits = self.linear(h_t[-1])\n                probs = logits.softmax(dim=-1)\n                pred = torch.multinomial(probs, 1) # -> (1,1)\n                idx = torch.cat([idx, pred], dim=1)\n                idx_prod = torch.unsqueeze(idx[:, -1], 0)\n        elif index == 1: ##### VERY SLOW\n            for t in range(max_length):      \n                logits, _ = self(idx) # logits -> 1, 1, (vocab_size)\n                logits = logits[:,-1,:]\n                probs = logits.softmax(dim=-1)\n                pred = torch.multinomial(probs, 1) # -> (1,1)\n                idx = torch.cat([idx, pred], dim=1)\n        elif index == 2: ### Has Best perfomance\n            for t in range(max_length):  \n                idx_cond = idx[:, -time_length:]\n                logits, _ = self(idx_cond) # logits -> 1, 1, (vocab_size)\n                logits = logits[:,-1,:]\n                probs = logits.softmax(dim=-1)\n                pred = torch.multinomial(probs, 1) # -> (1,1)\n                idx = torch.cat([idx, pred], dim=1)\n                \n        return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:24:02.158559Z","iopub.execute_input":"2024-11-06T23:24:02.159092Z","iopub.status.idle":"2024-11-06T23:24:02.178573Z","shell.execute_reply.started":"2024-11-06T23:24:02.159044Z","shell.execute_reply":"2024-11-06T23:24:02.177132Z"}},"outputs":[],"execution_count":370},{"cell_type":"code","source":"model = BgramRNN()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:24:02.498447Z","iopub.execute_input":"2024-11-06T23:24:02.498916Z","iopub.status.idle":"2024-11-06T23:24:02.507674Z","shell.execute_reply.started":"2024-11-06T23:24:02.498871Z","shell.execute_reply":"2024-11-06T23:24:02.506488Z"}},"outputs":[],"execution_count":371},{"cell_type":"code","source":"optim = torch.optim.Adam(model.parameters(), lr=lr)\nfor iter in range(iters):\n    x, y = get_batch('train')\n    out, loss = model(x, y)\n    if iter % val_interval == 0 or iter == iters-1:\n        val_loss = estimate_loss()\n        print(f\"Iter number: {iter}, train loss: {loss.item():.4f}, val loss:{val_loss:.4f}\")\n    model.zero_grad()\n    loss.backward()\n    optim.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T22:49:37.356853Z","iopub.execute_input":"2024-11-06T22:49:37.357869Z","iopub.status.idle":"2024-11-06T22:49:46.774036Z","shell.execute_reply.started":"2024-11-06T22:49:37.357813Z","shell.execute_reply":"2024-11-06T22:49:46.772143Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Iter number: 0, train loss: 1.5617, val loss:1.7613\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[279], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[1;32m      3\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     out, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m val_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m iters\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      6\u001b[0m         val_loss \u001b[38;5;241m=\u001b[39m estimate_loss()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[276], line 19\u001b[0m, in \u001b[0;36mBgramRNN.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# x -> (B, T), target -> (B, T)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membd(x) \u001b[38;5;66;03m# -> (B, T, embd_dim)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     output, h_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# output -> (B, T, hidden), h_t -> (B, hidden)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(output) \u001b[38;5;66;03m# -> (B, T, n_embd)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:592\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 592\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_tanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    597\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m    598\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":279},{"cell_type":"code","source":"context = torch.zeros((1,1), dtype=torch.long)\nprint(decode(model.generate(context, max_length=300, index=2)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:34:37.744584Z","iopub.execute_input":"2024-11-06T23:34:37.745097Z","iopub.status.idle":"2024-11-06T23:34:41.072360Z","shell.execute_reply.started":"2024-11-06T23:34:37.745048Z","shell.execute_reply":"2024-11-06T23:34:41.070929Z"}},"outputs":[{"name":"stdout","text":"\nMy hours, I sea; I were, good Barlowy.\n\nSICINIUS:\nVold for hands leed us tespiser:\nHus, I in fight. As when that I that she are to the gentle to facce our graciof.\nThe workch'd,\nComen my lies and though mine.\n\nSICINIUS:\nWith thoughts stay.\n\nCORIOLAND:\nLord you we lizine holy untrestines, will I bein\n","output_type":"stream"}],"execution_count":425},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"code","source":"time_length = 25\nbatch_size = 256\n\ndef get_batch(split):\n    if split == 'train':\n        data = train_data\n    else:\n        data = val_data\n    idx = torch.randint(0, len(data) - time_length, size=(batch_size, 1))\n    x = torch.stack([data[ix:ix + time_length] for ix in idx])\n    y = torch.stack([data[ix + 1:ix + 1 + time_length] for ix in idx])\n\n    return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:02:17.993877Z","iopub.execute_input":"2024-11-07T00:02:17.994291Z","iopub.status.idle":"2024-11-07T00:02:18.001457Z","shell.execute_reply.started":"2024-11-07T00:02:17.994255Z","shell.execute_reply":"2024-11-07T00:02:18.000437Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"embd_dim = 128\nn_embd = vocab_size\nhidden_size = 256\nlr = 3e-4\niters = 100000\nval_iters = 1000\nn_layer = 5\ndropout=0.2\n\nclass BgramLSTM(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embd = nn.Embedding(n_embd, embd_dim)\n        self.lstm = nn.LSTM(embd_dim, hidden_size, batch_first=True, num_layers=n_layer, dropout=dropout)\n        self.linear = nn.Linear(hidden_size, n_embd, bias=False)\n\n    def forward(self, x, target=None):\n        # x -> (B, T), target -> (B, T)\n        x = self.embd(x) # -> (B, T, embd_dim)\n        output, (h_t, c_t) = self.lstm(x) # output -> (B, T, hidden), h_t -> (B, hidden)\n        logits = self.linear(output) # -> (B, T, n_embd)\n\n        if target is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C) # -> (B*T, C)\n            target = target.view(B*T) # -> (B*T, 1)\n            loss = F.cross_entropy(logits, target)\n\n        return logits, loss\n\n    def generate(self, idx, max_length, index=0):\n        # idx -> (1, 1)\n        if index == 0: #The fastest\n            h_t = torch.zeros(n_layer, idx.shape[0], hidden_size, device=device)\n            c_t = torch.zeros(n_layer, idx.shape[0], hidden_size, device=device)\n            idx_prod = idx\n            for t in range(max_length): ### The fastest\n                x = self.embd(idx_prod) # -> (B, T, embd_dim)\n                output, (h_t, c_t) = self.lstm(x, (h_t, c_t)) # output -> (B, T, hidden), h_t -> (B, hidden)\n                logits = self.linear(h_t[-1])\n                probs = logits.softmax(dim=-1)\n                pred = torch.multinomial(probs, 1) # -> (1,1)\n                idx = torch.cat([idx, pred], dim=1)\n                idx_prod = torch.unsqueeze(idx[:, -1], 0)\n        elif index == 1: ##### VERY SLOW\n            for t in range(max_length):      \n                logits, _ = self(idx) # logits -> 1, 1, (vocab_size)\n                logits = logits[:,-1,:]\n                probs = logits.softmax(dim=-1)\n                pred = torch.multinomial(probs, 1) # -> (1,1)\n                idx = torch.cat([idx, pred], dim=1)\n        elif index == 2: ### Has Best perfomance\n            for t in range(max_length):  \n                idx_cond = idx[:, -time_length:]\n                logits, _ = self(idx_cond) # logits -> 1, 1, (vocab_size)\n                logits = logits[:,-1,:]\n                probs = logits.softmax(dim=-1)\n                pred = torch.multinomial(probs, 1) # -> (1,1)\n                idx = torch.cat([idx, pred], dim=1)\n                \n        return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:14:48.748307Z","iopub.execute_input":"2024-11-07T00:14:48.748700Z","iopub.status.idle":"2024-11-07T00:14:48.764312Z","shell.execute_reply.started":"2024-11-07T00:14:48.748664Z","shell.execute_reply":"2024-11-07T00:14:48.763380Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = BgramLSTM()\nmodel = model.to(device)\nprint(f\"Total number of parameters: {sum(p.numel() for p in model.parameters())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:14:50.376562Z","iopub.execute_input":"2024-11-07T00:14:50.376940Z","iopub.status.idle":"2024-11-07T00:14:50.411232Z","shell.execute_reply.started":"2024-11-07T00:14:50.376904Z","shell.execute_reply":"2024-11-07T00:14:50.410315Z"}},"outputs":[{"name":"stdout","text":"Total number of parameters: 2525568\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"optim = torch.optim.AdamW(model.parameters(), lr=lr)\nfor iter in range(iters):\n    x, y = get_batch('train')\n    x, y = x.to(device), y.to(device)\n    out, loss = model(x, y)\n    if iter % val_interval == 0 or iter == iters-1:\n        val_loss = estimate_loss()\n        print(f\"Iter number: {iter}, train loss: {loss.item():.4f}, val loss:{val_loss:.4f}\")\n    model.zero_grad()\n    loss.backward()\n    optim.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:30:33.835593Z","iopub.execute_input":"2024-11-07T00:30:33.835984Z","iopub.status.idle":"2024-11-07T00:35:44.072261Z","shell.execute_reply.started":"2024-11-07T00:30:33.835949Z","shell.execute_reply":"2024-11-07T00:35:44.070842Z"}},"outputs":[{"name":"stdout","text":"Iter number: 0, train loss: 1.3176, val loss:1.5683\nIter number: 1000, train loss: 1.3280, val loss:1.5694\nIter number: 2000, train loss: 1.3507, val loss:1.5682\nIter number: 3000, train loss: 1.3426, val loss:1.5684\nIter number: 4000, train loss: 1.3222, val loss:1.5667\nIter number: 5000, train loss: 1.3130, val loss:1.5681\nIter number: 6000, train loss: 1.3132, val loss:1.5704\nIter number: 7000, train loss: 1.3079, val loss:1.5684\nIter number: 8000, train loss: 1.2980, val loss:1.5726\nIter number: 9000, train loss: 1.2497, val loss:1.5707\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 11\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:227\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         state_steps,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:767\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 767\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:602\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[0;32m--> 602\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_div_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n\u001b[1;32m    604\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(\n\u001b[1;32m    605\u001b[0m     device_params,\n\u001b[1;32m    606\u001b[0m     device_exp_avgs,\n\u001b[1;32m    607\u001b[0m     exp_avg_sq_sqrt,\n\u001b[1;32m    608\u001b[0m     step_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    609\u001b[0m )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":43},{"cell_type":"code","source":"context = torch.zeros((1,1), dtype=torch.long, device=device)\nprint(decode(model.generate(context, max_length=10000, index=2)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:36:15.499700Z","iopub.execute_input":"2024-11-07T00:36:15.500550Z","iopub.status.idle":"2024-11-07T00:36:36.712656Z","shell.execute_reply.started":"2024-11-07T00:36:15.500513Z","shell.execute_reply":"2024-11-07T00:36:36.711673Z"}},"outputs":[{"name":"stdout","text":"\n\nWARWICK:\nNo more shows well will stain:\nI'll not treachery what I have fool'd, and unknown as you to a slower.\n\nPOMPEY:\nNow let's hear it, boy!\n\nRATCLIFF:\nNay, if it plense your mother.\n\nKING EDWARD IV:\nBut ass others, I had but by the spirity.\n\nBUCKINGHAM:\nBad tormany hour that follows is plain, yet he would remmal here: he believe thee to:\nprocove this policy's disposition: therefore\nto be truble that houses and owe\nBy over first opinion, though thou didst guess to departed to\nstand!\nGood business, you all; and thou wilt grant thy steeds\nand so by right these with him to ask, and geint being the noble men do do I.\n\nQUEEN ELIZABETH:\nPlantagenet, that the time lives enryardly suffice with hoarding: a wind;\nThey rather it be, the drum,\nI say ash up the flowers his second crown,\nAnd frame our fellowships of fire: he'll to ervy nothing; and sure lothes untimely brook wakes,\nAnd transport our treaty; and my strew glisty course and their virthrow me us well.\nThou, just you may shine to believe\nFrom you oft within, that say you give thee I lad o' him and we we not; misicaltle.\n\nSecond Gentleman:\nHe considered with that, but he\nchanmer withal from her granding\nfalrey in brief in witle all:\nDoes correct, the ground may make it with woe.\nI serve down, lord, nor honourablous spirit wilt thou accept thy denish dam with thy baseness range, my son many is the quarrel to this promise of\nstrict-men-brow with me to this another comfort;\nIt lou'ds not farewell; and make my sir\nJich issue of old words,\nAnon and your old somety, and poor at that scord against him\nAnd both from than the victory\nStruck thou the law something through no suchseforable,\nIs my mighty end?\n\nDERBY:\nThe gates of many mouth, you have had my coal\nTheir tongues cliemine mildreps my friend\nTo breathe their officers all witness\nLike heaven, as might defil\nA break a terminal and that banish'd'\nSmooth:\nWhat same health was to effise for worethbony. There's 'em and call us no heart\nAre come of death,\nWe'll begin as strangely arms in a man: I beseech you with thy\nsouls, good Fetliguling bloody restation willinglound\nDust shall I will be throw-froon\nTo Bianca, better spceed fortune's wall,\nha? He hash boysouklep him weather,\nWhich commited to Paulina,\nTo pardon thee away.\nI have at your starsa.' What, stay all said!\nWhere is it forsworn, believe your heart's dist cospinical as\nan ease you depart begin.\n\nLUCIO:\nMine, if algones to your counsel:\nThe fellowers of my man. Chamable,\nI am for the business am to thy with mine honour, sir, you hanged not to believe find\nWon of I have commanded wonderly ago.\n\nBUCKINGHAM:\nWhat? arpus, he shall,\nTake as ever drown he is beaten their movex. My Lord Aumerle,\nIt was some Richmond, how his damseblies\nplucker and readiness me and pretty traitor to his subject shall be more of mine issue;\nFor Warwick's officience, gentle for a princely 'spark drink to tire all earth.\n\nCOMINIUS:\nBring me so rewardine.\n\nKING RICHARD III:\nThen three Slandan's fell'd.\n\nDUKE OFEY:\nFirst Caculvest; farewell, none on her brow\nWill give her lentie's late,\nAnd well want the petticular Roccase your hearts temple\nThat I was forgot's, the bed divine\nyou must meat as the hoope? I'll lay some great\nwidow of the chaspolent springs of heaven should do you with themselves to answer to him down:\nIn yielded to my causes, Marcius can horse homely fit it not sharp. Come, can you shed to fleath.\n\nFERTIUS:\nI will day it dismes.\n3 KING HENRY VI\n\nJULIET:\nSilinesss that I, stars,\nDeserve his hand of your self.\n\nClown:\nThat she is banish'd,\nNor filled by the day will wear you for me we\nore an old death. Hears friends,\nHath dissembled here in Rome. If you shall keep it, and love thy ireful one invipina mithe;\nFor he hath been\nFudbided with his long made her at\nmesseble clusizardly made as his limbs.\n\nKING RICHARD III:\nBut where he is, sirrah; that you wonder to the sow\nWill be-histed to my rebel.\n\nKING RICHARD III:\nWho art thou worthy times dronks\nto 't an all reward:  thou fitting for the leavest King Herbing? I knew not my tongue's dead.\n\nHay:\nTrue pale, nought by my request?\nThou crit Officer:\nNay, he dost thou follow I can unctuary for the matter:\nAway to be presses a night.\nBut O, that He sluedest, queen.\n\nMENENIUS:\nHeavy 'not do how.\n\nFirst Keeper:\nWe can by nothing for embraced in't.\nO,, fellow, not for the excentio, are gentle man till thou\nshall wish both the prosperous infestion: attend you intelliging frown\nto my sir am stand; and for him I love thy father in the old soul\nAgainst me again of thine issue,\nHuse against made vain were, which you must become to a mond as\nWill enemy's\nUnless my gracious steelithee spirit!\n\nPOLIXENES:\nBelieve Clarence, with slagamise slow-sweeter willwish by crown, waterford, I were back? rise, shall I prove a traitor of thee, take up the wath, make her brothers--be gale?\n\nLORD FITZWATER:\nO, this is the lifingly age.\nBut is at sorrow in love, brother is a bred to\nhouse. I fear breaks; this deep fire\nRutely that you set down a damn'd prema closely than the soul\nThat to me bristle now not\nbutest Henry, their hearts live and prunes\nFrom special bragging to his found marriage begins with heavy.\n\nCOMINIUS:\nThis day.\n\nPAULINA:\nHow! go yonder outs! Slaves\nWith his knee vow with she father, I see 'th-lew with thousand there\nis pawy flowers with me; take mercy with his face,\nFor that, in virtue-hassent for us.\nBut more load on their fair royal tade,\nWith what is children by the field.\n\nDUKE VINCENTIO:\nAs withal, here shall you send--have to dipe your cause besides, forbear the dove do pupil on,\nDo would but peace are cold;\nWhich heasing my regors; but nu mocking of mine eyes; and, sir.\n\nShepherd:\nThese trembling coining, thus the cousins to the great daughter's loss.\n\nMENENIUS:\nNay, take it!\nHow cannot death a dead, our lord,\nWhere are him not, peers, will not how thy seat that doth\nshe would all commident to the wills;\nWould say that doleful master: see, whose courtesy\nThe walls he died thee graceful dreems grow to the Lord Augentrus strigle bendon of him back again?\nCome, corlful my breast, go\nSo disperse; therefore attend you in this news doth not do three pedity,\nWe must love the grown instruments their mind my father's king.\nNow, let yime, welcome your unconselssiming.\n\nMENENIUS:\nWhere we must be not\nnot thy breath in tender son is too mismankling truth: worthy Prince of York\nAnd when I speak it; but now more others,\nPut in their corp,--having me the slaughter,\nAnd invering your to. I am this in doom; revenge him\nIn time of gentleman will for scales\nShortly saw it no more ruen!\n\nJULIET:\nO to go, madif you have ransom our own more roon,\nWith writtingners according.\n\nYORK:\nNor I, here are no soldier,\nWho issue from wemtern'd himself which there he\ndid spring we give me to the supur-hinded maidenhily and let\nYourself agony.\n\nRIVERS:\nSee you more till he sometimes our loves,\nThat Rouse to be grieves she's not to me,\nAnd happy say you said.\n\nPAULINA:\nTribuneslor, more beats, so high laze the other's' term'd with amaze,\nbut we could to dry, my great afford\nIn graces are plainly.\nAnointed here it wrong is left bounded, and till I, velgeanament,\nIn teventiOf intelligation last not not to smell,\nTo resign to dowbranch they had mute out\nTo beloved: I will know thy lust, shall sleep your city's affect\nEven in the much prince made has in hellet\nAs let nine put upon her flowers,\nthat the man with not my soul's wife;\nBetter shall the man-mookeen.\n\nQUEEN ELIZABETH:\nBe grieves, the jredation of the cause on.\n\nHENRY PERCY:\nReady with us, an art thou aphers then,\nIf King Henry and Bretic last,\nThe first nature of his brother Dido some arm\nAnd welcome my father's duty is that of your father?\n\nSecond Citizen:\nWhat carry, fortune should a gentlewoman.\nBut, give me door: what? but we mean it!\nThe bastory done than your seat as mine hope continueless, that do wed\nMy children defecting him at,\nAnd I am missage with this heir\nWith press's fetlaugh is a willed\nbear this earth and his royal lord.\n\nSICINIUS:\nIndeed, I am wife'd\nWho shall beat their feltiral\nTo be ruled, true, allow'd us; one may lie\nBurdied's death of their attendances,\nAnd in the king, my lord, so offers to your mother?\n\nGLOUCESTER:\nSint of York and Bar of Lack Srophen; old Clare have made here\n\nPOMPEY:\nSir, let us not our out:\nI am a downlow.\n\nDUKE VINCENTIO:\nNeighbours with help, starveth, and meet him.\nCommend me, madam:\nI will not like you, good sir,\nWhose love is a churchyard\nWere under instial, can me:\nA faghorm, am I have I do scold him:\nWe am not short thickling nurse will to clear my most mouth,\nWere I have't been an Edward and Siland Lord Angelo.\n\nCLIFFORD:\nGo the Richard fight-wingier;\nFollows you women by yous husband:\nAnd, sir, but it were foolish fraicture, that's not best thou go,\nAnd show my best knave, the earthful ages of Rome; for here for the sleeper without\nexecutionary, what our Ady's, which now at life?\n\nTYBALT:\nSteal more for Blys, none school me\nBoth to me, sir, it is.\n\nPRINCE EDWARD:\nNow he may semund--found out these words.\n\nHASTINGS:\nFear for contempt.\n\nAUTOLYCUS:\nNo, his tent to Rome since he is a kis,\nThat I want no interprisure; withdraw thy gracious life.\n\nQUEEN ELIZABETH:\nTo his kingly for I must needs make his charged but die\nsomething done to bring you anon,\nUnlerged us better, then, or to your dear Margaret, had even yet\nBetrockest thou do, and wherely-bed of madam; your honour and you accender your houses\nI Lord Hastings, and others: you have ever\ntell me, and as for his children. Thou wear justoo's face;\nThat I and my grace be good good morn right.\nO misterning swords, madam:\nOreds, what I love: wart our trial\nTo you afford I am told.\n\nClown:\nNot need, go tell\nMardies: but I have your\nbrow\nis Petature spring, and stay about--\nThe gates are tells it. Let thee take your hope-fickles grant ough twenty\nthousand an hour confess himself, gentlemen,\nBeing so marcharch to her I very waid and rage harm,\nTo have my calting with the wit\nMy disease, and much to do caather,\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"```\nmodel 1:\nBgramRNN(\r\n  (embd): Embedding(65, 65)\r\ntime_length = 10)\n\nresults: train loss: 2.4077, val loss: 2.5242\n\nmod 2elBgramRNN(\r\n  (embd): Embedding(65, 05\n  (linear): Linear(in_features=60, out_features=65, bias=False))\r\ntime_length = 10)\n)\n\nresults: train lo2.21904077, val lo2.49865986\n\nm 3odel:\nBgramRNN(\n  (embd): Embedding(65, 60)\n  (rnn): RNN(60, 5, batch_first=True)\n  (linear): Linear(in_features=5, out_features=65, bias=Falsetime_length = 10)\n)\n\nresults: train loss: 2.4700, val loss: 2.5835\n\n\nm 4odel:\nBgramRNN(\n  (embd): Embedding(65, 60)\n  (rnn): RNN(60, 60, batch_first=True)\n  (linear): Linear(in_features=60, out_features=65, bias=Falsetime_length = 10)\n)\n\nresults: train loss: 1.7105, val loss: 2.1113\n\n\nm 5odel:\nBgramRNN(\r\n  (embd): Embedding(65, 64)\r\n  (rnn): RNN(64, 100, num_layers=2, batch_first=True)\r\n  (linear): Linear(in_features=100, out_features=65, bias=Fatime_length = 10lse)\r\n)\n\nresultrain loss: 1.7024, val loss:1.\n\n\nmodel 6:\nBgramRNN(\r\n  (embd): Embedding(65, 128)\r\n  (rnn): RNN(128, 128, num_layers=3, batch_first=True)\r\n  (linear): Linear(in_features=128, out_features=65, bias=False)\r\n)\ntime_length = 25\nresultrain loss: 1.6046, val loss:1.7603\n\n\nmodel 7:\nBgramLSTM(\r\n  (embd): Embedding(65, 128)\r\n  (lstm): LSTM(128, 128, num_layers=3, batch_first=True)\r\n  (linear): Linear(in_features=128, out_features=65, bias=False\nnumber of parameters: 412928)\r\n)\ntim\ntime_length = 25\n rain loss: 1.3582, val loss:1.6162\ns\nmodel 8:\nBgramLSTM(\r\n   (embd): Embedding(65, 128)\r\n   (lstm): LSTM(128, 256, num_layers=5, batch_first=True)\r\n   (linear): Linear(in_features=256, out_features=65, bias=False)\rnumber\n\r\n )\nnumber of 2525568ters: 412928\ntime_length = 25\nresults:train loss: 1.2856, val loss:1.6423 lmodel 9:\nBgramLSTM(\n   (embd): Embedding(65, 128)\n   (lstm): LSTM(128, 256, num_layers=5, batch_first=True, dropout=0.2)\n   (linear): Linear(in_features=256, out_features=65, bias=False)\n ) + AdamW optimizer\nnumber of parameters: 2525568\ntime_length = 25\nresults: train loss: 1.3426, val loss:1.5684oss:1.6162\n\n\n:1.7603931893181113\n\n```","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}