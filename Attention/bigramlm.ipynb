{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:48.142396Z","iopub.execute_input":"2024-11-04T17:27:48.142948Z","iopub.status.idle":"2024-11-04T17:27:49.517946Z","shell.execute_reply.started":"2024-11-04T17:27:48.142804Z","shell.execute_reply":"2024-11-04T17:27:49.516399Z"}},"outputs":[{"name":"stdout","text":"--2024-11-04 17:27:49--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: 'input.txt'\n\ninput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n\n2024-11-04 17:27:49 (46.3 MB/s) - 'input.txt' saved [1115394/1115394]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"with open('/kaggle/working/input.txt', 'r') as f:\n    text = f.read()\nprint(text[:1000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:49.520334Z","iopub.execute_input":"2024-11-04T17:27:49.520732Z","iopub.status.idle":"2024-11-04T17:27:49.530289Z","shell.execute_reply.started":"2024-11-04T17:27:49.520694Z","shell.execute_reply":"2024-11-04T17:27:49.528664Z"}},"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:49.531825Z","iopub.execute_input":"2024-11-04T17:27:49.532684Z","iopub.status.idle":"2024-11-04T17:27:49.572535Z","shell.execute_reply.started":"2024-11-04T17:27:49.532635Z","shell.execute_reply":"2024-11-04T17:27:49.570841Z"}},"outputs":[{"name":"stdout","text":"\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n65\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"stoi = {i: j for i, j in enumerate(chars)}\nitos = {j: i for i, j in enumerate(chars)}\n\nencode = lambda input: [itos[ch] for ch in input]\ndecode = lambda input: ''.join([stoi[ch] for ch in input])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:49.657586Z","iopub.execute_input":"2024-11-04T17:27:49.658332Z","iopub.status.idle":"2024-11-04T17:27:49.664867Z","shell.execute_reply.started":"2024-11-04T17:27:49.658283Z","shell.execute_reply":"2024-11-04T17:27:49.663518Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(encode(\"hi there\"))\nprint(decode(encode(\"hi there\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:50.376864Z","iopub.execute_input":"2024-11-04T17:27:50.377325Z","iopub.status.idle":"2024-11-04T17:27:50.383966Z","shell.execute_reply.started":"2024-11-04T17:27:50.377279Z","shell.execute_reply":"2024-11-04T17:27:50.382436Z"}},"outputs":[{"name":"stdout","text":"[46, 47, 1, 58, 46, 43, 56, 43]\nhi there\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"len(encode(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:52.128417Z","iopub.execute_input":"2024-11-04T17:27:52.128877Z","iopub.status.idle":"2024-11-04T17:27:52.245229Z","shell.execute_reply.started":"2024-11-04T17:27:52.128835Z","shell.execute_reply":"2024-11-04T17:27:52.244074Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1115394"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import torch\ndata = torch.tensor(encode(text), dtype = torch.long)\nprint(data.shape, data.dtype)\nprint(data[:1000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:52.538972Z","iopub.execute_input":"2024-11-04T17:27:52.539423Z","iopub.status.idle":"2024-11-04T17:27:55.983256Z","shell.execute_reply.started":"2024-11-04T17:27:52.539375Z","shell.execute_reply":"2024-11-04T17:27:55.982064Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1115394]) torch.int64\ntensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"n = int(0.8 * len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:55.985768Z","iopub.execute_input":"2024-11-04T17:27:55.986670Z","iopub.status.idle":"2024-11-04T17:27:55.992348Z","shell.execute_reply.started":"2024-11-04T17:27:55.986611Z","shell.execute_reply":"2024-11-04T17:27:55.990864Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"torch.manual_seed(1337)\nbatch_size = 4\nblock_size = 8\n\ndef get_batch(split):\n    data = train_data if split == 'train' else val_data\n    ix = torch.randint(0, len(data) - block_size, (batch_size, 1))\n    add_ix = torch.arange(1, block_size).repeat(batch_size, 1)\n    final_ix = torch.cat((ix, ix + add_ix), dim=1)\n    xb = data[final_ix]\n    yb = data[final_ix +  1]\n    return xb, yb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:55.993993Z","iopub.execute_input":"2024-11-04T17:27:55.994740Z","iopub.status.idle":"2024-11-04T17:27:56.010298Z","shell.execute_reply.started":"2024-11-04T17:27:55.994685Z","shell.execute_reply":"2024-11-04T17:27:56.009099Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"xb, yb= get_batch('train')\nprint('inputs:')\nprint(xb.shape)\nprint(xb)\nprint('targets:')\nprint(yb.shape)\nprint(yb)\nprint('------')\n\nfor i in range(batch_size): \n    for j in range(1, block_size + 1):\n        print(f\"When input is {xb[i, :j].tolist()} the target is {yb[i, j-1]}\")\n        print(f'When input is \"{decode(xb[i, :j].tolist())}\" the target is \"{decode([yb[i, j-1].item()])}\"')\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:56.012547Z","iopub.execute_input":"2024-11-04T17:27:56.012992Z","iopub.status.idle":"2024-11-04T17:27:56.073453Z","shell.execute_reply.started":"2024-11-04T17:27:56.012946Z","shell.execute_reply":"2024-11-04T17:27:56.072239Z"}},"outputs":[{"name":"stdout","text":"inputs:\ntorch.Size([4, 8])\ntensor([[58, 63,  8,  0,  0, 19, 24, 27],\n        [39, 59, 45, 46, 58,  1, 46, 43],\n        [49, 43, 57,  1, 53, 50, 42,  1],\n        [52, 41, 47, 43, 52, 58,  1, 56]])\ntargets:\ntorch.Size([4, 8])\ntensor([[63,  8,  0,  0, 19, 24, 27, 33],\n        [59, 45, 46, 58,  1, 46, 43,  1],\n        [43, 57,  1, 53, 50, 42,  1, 46],\n        [41, 47, 43, 52, 58,  1, 56, 47]])\n------\nWhen input is [58] the target is 63\nWhen input is \"t\" the target is \"y\"\nWhen input is [58, 63] the target is 8\nWhen input is \"ty\" the target is \".\"\nWhen input is [58, 63, 8] the target is 0\nWhen input is \"ty.\" the target is \"\n\"\nWhen input is [58, 63, 8, 0] the target is 0\nWhen input is \"ty.\n\" the target is \"\n\"\nWhen input is [58, 63, 8, 0, 0] the target is 19\nWhen input is \"ty.\n\n\" the target is \"G\"\nWhen input is [58, 63, 8, 0, 0, 19] the target is 24\nWhen input is \"ty.\n\nG\" the target is \"L\"\nWhen input is [58, 63, 8, 0, 0, 19, 24] the target is 27\nWhen input is \"ty.\n\nGL\" the target is \"O\"\nWhen input is [58, 63, 8, 0, 0, 19, 24, 27] the target is 33\nWhen input is \"ty.\n\nGLO\" the target is \"U\"\n\nWhen input is [39] the target is 59\nWhen input is \"a\" the target is \"u\"\nWhen input is [39, 59] the target is 45\nWhen input is \"au\" the target is \"g\"\nWhen input is [39, 59, 45] the target is 46\nWhen input is \"aug\" the target is \"h\"\nWhen input is [39, 59, 45, 46] the target is 58\nWhen input is \"augh\" the target is \"t\"\nWhen input is [39, 59, 45, 46, 58] the target is 1\nWhen input is \"aught\" the target is \" \"\nWhen input is [39, 59, 45, 46, 58, 1] the target is 46\nWhen input is \"aught \" the target is \"h\"\nWhen input is [39, 59, 45, 46, 58, 1, 46] the target is 43\nWhen input is \"aught h\" the target is \"e\"\nWhen input is [39, 59, 45, 46, 58, 1, 46, 43] the target is 1\nWhen input is \"aught he\" the target is \" \"\n\nWhen input is [49] the target is 43\nWhen input is \"k\" the target is \"e\"\nWhen input is [49, 43] the target is 57\nWhen input is \"ke\" the target is \"s\"\nWhen input is [49, 43, 57] the target is 1\nWhen input is \"kes\" the target is \" \"\nWhen input is [49, 43, 57, 1] the target is 53\nWhen input is \"kes \" the target is \"o\"\nWhen input is [49, 43, 57, 1, 53] the target is 50\nWhen input is \"kes o\" the target is \"l\"\nWhen input is [49, 43, 57, 1, 53, 50] the target is 42\nWhen input is \"kes ol\" the target is \"d\"\nWhen input is [49, 43, 57, 1, 53, 50, 42] the target is 1\nWhen input is \"kes old\" the target is \" \"\nWhen input is [49, 43, 57, 1, 53, 50, 42, 1] the target is 46\nWhen input is \"kes old \" the target is \"h\"\n\nWhen input is [52] the target is 41\nWhen input is \"n\" the target is \"c\"\nWhen input is [52, 41] the target is 47\nWhen input is \"nc\" the target is \"i\"\nWhen input is [52, 41, 47] the target is 43\nWhen input is \"nci\" the target is \"e\"\nWhen input is [52, 41, 47, 43] the target is 52\nWhen input is \"ncie\" the target is \"n\"\nWhen input is [52, 41, 47, 43, 52] the target is 58\nWhen input is \"ncien\" the target is \"t\"\nWhen input is [52, 41, 47, 43, 52, 58] the target is 1\nWhen input is \"ncient\" the target is \" \"\nWhen input is [52, 41, 47, 43, 52, 58, 1] the target is 56\nWhen input is \"ncient \" the target is \"r\"\nWhen input is [52, 41, 47, 43, 52, 58, 1, 56] the target is 47\nWhen input is \"ncient r\" the target is \"i\"\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(1337)\n\n\nclass BigramLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, vocab_size)\n\n    def forward(self, idx, targets=None):\n        \n        logits = self.embed(idx)\n        if targets is None:\n            loss = None\n        else:\n            \n            #logits shape (B, T), targets shape (B, T)\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n        \n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            logits, loss = self(idx)\n            logits = logits[:,-1,:]\n            probs = F.softmax(logits, dim=1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat([idx, idx_next], dim=1)\n\n        return idx\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:27:56.869881Z","iopub.execute_input":"2024-11-04T17:27:56.870316Z","iopub.status.idle":"2024-11-04T17:27:56.882697Z","shell.execute_reply.started":"2024-11-04T17:27:56.870274Z","shell.execute_reply":"2024-11-04T17:27:56.881195Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"bgram = BigramLanguageModel()\nout, loss = bgram(xb, yb)\nprint(out.shape)\nprint(loss)\nprint(decode(bgram.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:28:32.191986Z","iopub.execute_input":"2024-11-04T17:28:32.192436Z","iopub.status.idle":"2024-11-04T17:28:32.216213Z","shell.execute_reply.started":"2024-11-04T17:28:32.192390Z","shell.execute_reply":"2024-11-04T17:28:32.215036Z"}},"outputs":[{"name":"stdout","text":"torch.Size([256, 65])\ntensor(4.8250, grad_fn=<NllLossBackward0>)\n\n,jm-TFpfgoIZiJpwwjKTToBsu?&.HGnhoB;TMW'LGjj:&LEYqglbJHQPAuNI\nH';DSHkb sajI.Saw!gkxPVG3;EQxY&$m?riqxP\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"optim = torch.optim.Adam(bgram.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:28:32.609319Z","iopub.execute_input":"2024-11-04T17:28:32.610623Z","iopub.status.idle":"2024-11-04T17:28:32.615375Z","shell.execute_reply.started":"2024-11-04T17:28:32.610576Z","shell.execute_reply":"2024-11-04T17:28:32.614247Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"batch_size=32\nfor i in range(50000):\n    xb, yb = get_batch('train')\n    out, loss = bgram(xb, yb)\n    optim.zero_grad()\n    loss.backward()\n    optim.step()\n    \nprint(loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:28:33.092072Z","iopub.execute_input":"2024-11-04T17:28:33.092528Z","iopub.status.idle":"2024-11-04T17:29:14.125634Z","shell.execute_reply.started":"2024-11-04T17:28:33.092487Z","shell.execute_reply":"2024-11-04T17:29:14.124408Z"}},"outputs":[{"name":"stdout","text":"2.3840785026550293\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(decode(bgram.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:29:14.127623Z","iopub.execute_input":"2024-11-04T17:29:14.128020Z","iopub.status.idle":"2024-11-04T17:29:14.197588Z","shell.execute_reply.started":"2024-11-04T17:29:14.127979Z","shell.execute_reply":"2024-11-04T17:29:14.196392Z"}},"outputs":[{"name":"stdout","text":"\nRIED teshaithed caveit t y oth d s?\nALoroe?\nWit rsthangbeeliuppeced d br owiuce yo if faizencangnso, se Gixthet, The t ghoorife iowinicowinde s ten, d s cand\nOLINou focco INLII:\nRKiveronomanr:\nAhe mavesedouk has;\nWAllilld st prl blo y, m crd tl athe hoves tu w.\nRENGlfed, sthatherep uedany tht boficof wieve ss OFotealiny kece tre, t ofre.\nHe l my, the steyowen ofre Br jurou habu ffiff angerpourdofe thas:\n\nTEO,\nI's; sperd.\nAw:\nifoulathyesot al mio st llllontorticas sin chin wethenconk'sty ay outhr\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"x = torch.randn((4, 8, 2))\nB, T, C = x.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:35:36.138710Z","iopub.execute_input":"2024-11-04T14:35:36.139152Z","iopub.status.idle":"2024-11-04T14:35:36.146000Z","shell.execute_reply.started":"2024-11-04T14:35:36.139109Z","shell.execute_reply":"2024-11-04T14:35:36.144620Z"}},"outputs":[],"execution_count":323},{"cell_type":"code","source":"a = torch.tril(torch.ones((3,3)))\na = a / a.sum(dim=1, keepdim=True)\nb = torch.randint(0, 10, (3,2), dtype=torch.float)\nc = a @ b \nprint('a=')\nprint(a)\nprint('----')\nprint('b=')\nprint(b)\nprint('----')\nprint('c=')\nprint(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:50:21.649561Z","iopub.execute_input":"2024-11-04T14:50:21.650022Z","iopub.status.idle":"2024-11-04T14:50:21.663835Z","shell.execute_reply.started":"2024-11-04T14:50:21.649979Z","shell.execute_reply":"2024-11-04T14:50:21.662303Z"}},"outputs":[{"name":"stdout","text":"a=\ntensor([[1.0000, 0.0000, 0.0000],\n        [0.5000, 0.5000, 0.0000],\n        [0.3333, 0.3333, 0.3333]])\n----\nb=\ntensor([[2., 7.],\n        [5., 4.],\n        [1., 0.]])\n----\nc=\ntensor([[2.0000, 7.0000],\n        [3.5000, 5.5000],\n        [2.6667, 3.6667]])\n","output_type":"stream"}],"execution_count":367},{"cell_type":"code","source":"xbow = torch.zeros_like(x)\nfor i in range(B):\n    for j in range(T):\n        xbow[i,j] = torch.mean(x[i, :j+1], 0)\n\nprint(x.shape)\nprint(x[0])\nprint(xbow[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:36:34.867013Z","iopub.execute_input":"2024-11-04T14:36:34.867481Z","iopub.status.idle":"2024-11-04T14:36:34.879954Z","shell.execute_reply.started":"2024-11-04T14:36:34.867436Z","shell.execute_reply":"2024-11-04T14:36:34.878654Z"}},"outputs":[{"name":"stdout","text":"torch.Size([4, 8, 2])\ntensor([[ 0.5300,  0.5039],\n        [ 0.9270,  1.2622],\n        [-1.3136,  1.3034],\n        [ 2.6133,  1.0745],\n        [ 1.5550,  1.0246],\n        [ 0.2637,  0.0498],\n        [ 0.8311,  0.8405],\n        [-0.5485,  0.6853]])\ntensor([[0.5300, 0.5039],\n        [0.7285, 0.8830],\n        [0.0478, 1.0231],\n        [0.6892, 1.0360],\n        [0.8624, 1.0337],\n        [0.7626, 0.8697],\n        [0.7724, 0.8656],\n        [0.6073, 0.8430]])\n","output_type":"stream"}],"execution_count":325},{"cell_type":"code","source":"trils = torch.tril(torch.ones((T,T)))\ntrils = trils / trils.sum(dim=1, keepdim=True)\nxbow2 = trils @ x\nxbow2[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T14:43:15.809352Z","iopub.execute_input":"2024-11-04T14:43:15.809810Z","iopub.status.idle":"2024-11-04T14:43:15.821200Z","shell.execute_reply.started":"2024-11-04T14:43:15.809765Z","shell.execute_reply":"2024-11-04T14:43:15.819681Z"}},"outputs":[{"execution_count":347,"output_type":"execute_result","data":{"text/plain":"tensor([[0.5300, 0.5039],\n        [0.7285, 0.8830],\n        [0.0478, 1.0231],\n        [0.6892, 1.0360],\n        [0.8624, 1.0337],\n        [0.7626, 0.8697],\n        [0.7724, 0.8656],\n        [0.6073, 0.8430]])"},"metadata":{}}],"execution_count":347},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmax_iters = 5000\neval_interval = 300\nlr = 1e-3\neval_iters = 20\nn_embd = 32\n\n\nclass BigramLanguageModel(nn.Module):\n    def __init__(self): \n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, n_embd)\n        self.lm_layer = nn.Linear(n_embd, vocab_size)\n        self.pos_enc = nn.Embedding(block_size, n_embd)\n\n    def forward(self, idx, targets=None):\n        # idx shape (B, T)\n        (B, T) = idx.shape\n        token_embd = self.embed(idx)\n        if targets is None:\n            pos_embd = self.pos_enc(torch.tensor([0]))\n        else:\n            pos_embd = self.pos_enc(torch.arange(T))\n            \n        logits = self.lm_layer(token_embd + pos_embd)\n        \n        if targets is None:\n            loss = None\n        else:\n            #logits shape (B, T), targets shape (B, T)\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            logits, loss = self(idx)\n            logits = logits[:,-1,:]\n            probs = F.softmax(logits, dim=1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat([idx, idx_next], dim=1)\n\n        return idx\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:15:16.021498Z","iopub.execute_input":"2024-11-04T18:15:16.021967Z","iopub.status.idle":"2024-11-04T18:15:16.033532Z","shell.execute_reply.started":"2024-11-04T18:15:16.021929Z","shell.execute_reply":"2024-11-04T18:15:16.032196Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            logits, loss = model(X, targets=Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:15:16.814502Z","iopub.execute_input":"2024-11-04T18:15:16.815380Z","iopub.status.idle":"2024-11-04T18:15:16.822185Z","shell.execute_reply.started":"2024-11-04T18:15:16.815322Z","shell.execute_reply":"2024-11-04T18:15:16.820859Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"model = BigramLanguageModel()\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:15:17.034512Z","iopub.execute_input":"2024-11-04T18:15:17.034988Z","iopub.status.idle":"2024-11-04T18:15:17.042086Z","shell.execute_reply.started":"2024-11-04T18:15:17.034942Z","shell.execute_reply":"2024-11-04T18:15:17.040767Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"model.pos_enc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:44:33.884776Z","iopub.execute_input":"2024-11-04T18:44:33.885204Z","iopub.status.idle":"2024-11-04T18:44:33.892790Z","shell.execute_reply.started":"2024-11-04T18:44:33.885163Z","shell.execute_reply":"2024-11-04T18:44:33.891637Z"}},"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"Embedding(8, 32)"},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=lr*0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:15:33.970165Z","iopub.execute_input":"2024-11-04T18:15:33.970591Z","iopub.status.idle":"2024-11-04T18:15:33.976758Z","shell.execute_reply.started":"2024-11-04T18:15:33.970550Z","shell.execute_reply":"2024-11-04T18:15:33.975450Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"for iter in range(max_iters):\n\n    # every once in a while evaluate the loss on train and val sets\n    if iter % eval_interval == 0:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    # sample a batch of data\n    xb, yb = get_batch('train')\n\n    # evaluate the loss\n    logits, loss = model(xb, targets=yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T18:15:34.232446Z","iopub.execute_input":"2024-11-04T18:15:34.232881Z","iopub.status.idle":"2024-11-04T18:15:41.191668Z","shell.execute_reply.started":"2024-11-04T18:15:34.232839Z","shell.execute_reply":"2024-11-04T18:15:41.190540Z"}},"outputs":[{"name":"stdout","text":"step 0: train loss 2.4677, val loss 2.5389\nstep 300: train loss 2.4508, val loss 2.5187\nstep 600: train loss 2.4568, val loss 2.5190\nstep 900: train loss 2.4863, val loss 2.5189\nstep 1200: train loss 2.4439, val loss 2.4987\nstep 1500: train loss 2.4531, val loss 2.4786\nstep 1800: train loss 2.4661, val loss 2.5306\nstep 2100: train loss 2.4668, val loss 2.5241\nstep 2400: train loss 2.4532, val loss 2.5048\nstep 2700: train loss 2.4578, val loss 2.5146\nstep 3000: train loss 2.4610, val loss 2.5165\nstep 3300: train loss 2.4582, val loss 2.4831\nstep 3600: train loss 2.5053, val loss 2.5433\nstep 3900: train loss 2.4429, val loss 2.5004\nstep 4200: train loss 2.4887, val loss 2.5411\nstep 4500: train loss 2.4733, val loss 2.5106\nstep 4800: train loss 2.4684, val loss 2.5137\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(decode(model.generate(context, max_new_tokens=500)[0].tolist()))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T10:44:06.275844Z","iopub.execute_input":"2024-11-04T10:44:06.276274Z","iopub.status.idle":"2024-11-04T10:44:22.389838Z","shell.execute_reply.started":"2024-11-04T10:44:06.276231Z","shell.execute_reply":"2024-11-04T10:44:22.388357Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\nDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.8.0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import tiktoken\nenc = tiktoken.get_encoding(\"gpt2\")\nprint(enc.n_vocab)\ninput = \"oh sorryajh my bad!\"\neng_char_tokens = []\n\n#prove that tokenizer have to have a single charachter reprezentation\nfor char_idx in range(ord('A'), ord('Z') + 1):\n    eng_char_tokens.append(enc.encode(chr(char_idx))[0])\nfor char_idx in range(ord('a'), ord('z') + 1):\n    eng_char_tokens.append(enc.encode(chr(char_idx))[0])\n\nassert 26 * 2 == len(eng_char_tokens)\n\nprint(eng_char_tokens)\nprint(enc.encode(input))\nfor token in enc.encode(input):\n    print(enc.decode([token]))\nprint(enc.decode(enc.encode(input)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T10:55:22.418410Z","iopub.execute_input":"2024-11-04T10:55:22.419290Z","iopub.status.idle":"2024-11-04T10:55:22.430070Z","shell.execute_reply.started":"2024-11-04T10:55:22.419241Z","shell.execute_reply":"2024-11-04T10:55:22.428664Z"}},"outputs":[{"name":"stdout","text":"50257\n[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n[1219, 7926, 1228, 71, 616, 2089, 0]\noh\n sorry\naj\nh\n my\n bad\n!\noh sorryajh my bad!\n","output_type":"stream"}],"execution_count":53}]}